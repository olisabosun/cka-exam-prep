# Horizontal Pod Autoscaling (HPA)

## Scaling Types

### Manual Scaling
Scale deployments imperatively using kubectl:

```bash
kubectl scale deployment nginx-deployment --replicas 5
```

### Auto-scaling (HPA)
Horizontal Pod Autoscaler automatically scales pods based on metrics. Requires Metrics Server to be installed.

## Prerequisites

### Install Metrics Server
```bash
# Install Metrics Server for resource monitoring
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

# Verify installation
kubectl get pods -n kube-system | grep metrics-server
```

## Creating HPA

### Method 1: Imperative Creation

**Generate HPA YAML (dry-run):**
```bash
kubectl autoscale deployment nginx-deployment --cpu-percent=10 --min=3 --max=10 --dry-run=client -o yaml
```

**Create HPA directly:**
```bash
kubectl autoscale deployment nginx-deployment --cpu-percent=10 --min=3 --max=10
```

### Method 2: Declarative Creation

**Generate and save YAML:**
```bash
kubectl autoscale deployment nginx-deployment --cpu-percent=10 --min=3 --max=10 --dry-run=client -o yaml > myhpa.yaml
```

## HPA YAML Configuration

### Basic HPA (autoscaling/v1)

```yaml
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: nginx-deployment
spec:
  maxReplicas: 10
  minReplicas: 3
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nginx-deployment
  targetCPUUtilizationPercentage: 10
```

### Advanced HPA (autoscaling/v2beta2)

```yaml
apiVersion: autoscaling/v2beta2
kind: HorizontalPodAutoscaler
metadata:
  name: my-app
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: my-app
  minReplicas: 1
  maxReplicas: 5
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 66
```

### HPA with Stabilization Window (autoscaling/v2)

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: my-app
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nginx-deployment
  minReplicas: 3
  maxReplicas: 10
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 10
```

## HPA Management Commands

### View HPA Resources
```bash
kubectl get hpa
kubectl describe hpa my-app
```

### Check API Versions
```bash
kubectl api-resources | grep -i auto
```

### Apply HPA Configuration
```bash
kubectl apply -f myhpa.yaml
```

## Load Testing and Simulation

### Sample Deployment for Testing
Use this deployment to test HPA: https://github.com/networknuts/kubernetes/blob/master/ch-03-deployments/hpa-for-autoscaler-deployment.yaml

### Generate Load
1. **Get service IP:**
   ```bash
   kubectl get svc
   ```

2. **Run load generation in a new terminal:**
   ```bash
   while true; do curl http://10.108.205.211; done
   ```

3. **Monitor scaling:**
   ```bash
   kubectl get hpa
   kubectl get pods
   ```

4. **Stop load generation:**
   Press `Ctrl+C` in the load generation terminal

## HPA Behavior

### Scaling Triggers
- **Scale Up**: When CPU utilization exceeds target percentage
- **Scale Down**: When CPU utilization falls below target percentage
- **Stabilization Window**: Prevents rapid scaling oscillations (default: 300 seconds for scale down)

### Monitoring HPA
```bash
# Check HPA status
kubectl get hpa
kubectl describe hpa <hpa-name>

# Monitor pod scaling
kubectl get pods -w

# Check metrics
kubectl top pods
kubectl top nodes
```

## Important Notes

- **API Versions**: Use `autoscaling/v2` for production (includes stabilization windows)
- **Metrics Server**: Required for CPU-based autoscaling
- **Resource Requests**: Pods must have CPU requests defined for HPA to work
- **Cooldown Period**: Default stabilization window prevents thrashing
- **Target Types**: Can scale based on CPU, memory, or custom metrics

## Exam Tips

- Know the different autoscaling API versions
- Understand how to create HPA imperatively and declaratively
- Be familiar with troubleshooting HPA issues
- Know the prerequisites (Metrics Server, resource requests)
- Understand stabilization windows and their purpose

## References

- [Kubernetes HPA Documentation](https://kubernetes.io/docs/concepts/workloads/autoscaling/horizontal-pod-autoscale/)
- [NetworkNuts HPA Examples](https://github.com/networknuts/kubernetes/blob/master/ch-03-deployments/hpa-for-deployment-v2.yaml)

## Load Testing and Simulation

### Sample Deployment for Testing
Use this deployment to test HPA: https://github.com/networknuts/kubernetes/blob/master/ch-03-deployments/hpa-for-autoscaler-deployment.yaml

### Generate Load
1. **Get service IP:**
   ```bash
   kubectl get svc
   ```

2. **Run load generation in a new terminal:**
   ```bash
   while true; do curl http://10.108.205.211; done
   ```

3. **Monitor scaling:**
   ```bash
   kubectl get hpa
   kubectl get pods
   ```

4. **Stop load generation:**
   Press `Ctrl+C` in the load generation terminal

## HPA Management Commands

### View HPA Resources
```bash
kubectl get hpa
kubectl describe hpa my-app
```

### Check API Versions
```bash
kubectl api-resources | grep -i auto
```

### Apply HPA Configuration
```bash
kubectl apply -f myhpa.yaml
```

## HPA Behavior

### Scaling Triggers
- **Scale Up**: When CPU utilization exceeds target percentage
- **Scale Down**: When CPU utilization falls below target percentage
- **Stabilization Window**: Prevents rapid scaling oscillations (default: 300 seconds for scale down)

### Monitoring HPA
```bash
# Check HPA status
kubectl get hpa
kubectl describe hpa <hpa-name>

# Monitor pod scaling
kubectl get pods -w

# Check metrics
kubectl top pods
kubectl top nodes
```

## Important Notes

- **API Versions**: Use `autoscaling/v2` for production (includes stabilization windows)
- **Metrics Server**: Required for CPU-based autoscaling
- **Resource Requests**: Pods must have CPU requests defined for HPA to work
- **Cooldown Period**: Default stabilization window prevents thrashing
- **Target Types**: Can scale based on CPU, memory, or custom metrics

## Exam Tips

- Know the different autoscaling API versions
- Understand how to create HPA imperatively and declaratively
- Be familiar with troubleshooting HPA issues
- Know the prerequisites (Metrics Server, resource requests)
- Understand stabilization windows and their purpose

## References

- [Kubernetes HPA Documentation](https://kubernetes.io/docs/concepts/workloads/autoscaling/horizontal-pod-autoscale/)
- [NetworkNuts HPA Examples](https://github.com/networknuts/kubernetes/blob/master/ch-03-deployments/hpa-for-deployment-v2.yaml)
